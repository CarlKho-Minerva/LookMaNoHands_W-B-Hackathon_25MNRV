{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install together -q\n",
    "!pip install python-dotenv -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Together AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "client = Together()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are some fun things to do in New York? Who is Carl Kho?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W&B Weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weave\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "@weave.op()  # 游냏 Decorator to track requests\n",
    "def extract_fruit(sentence: str) -> dict:\n",
    "    client = OpenAI()\n",
    "    system_prompt = (\n",
    "        \"Parse sentences into a JSON dict with keys: fruit, color and flavor.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": sentence},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    extracted = response.choices[0].message.content\n",
    "    return json.loads(extracted)\n",
    "\n",
    "\n",
    "weave.init(\"intro-example\")  # 游냏\n",
    "sentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\n",
    "extract_fruit(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-100\",\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "    loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# Define a simple calculator tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Useful for multiplying two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Create an agent workflow with our calculator tool\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    [multiply],\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    system_prompt=\"You are a helpful assistant that can multiply two numbers.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Run the agent\n",
    "    response = await agent.run(\"What is 1234 * 4567?\")\n",
    "    display(Markdown(str(response)))\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.context import Context\n",
    "\n",
    "# create context\n",
    "ctx = Context(agent)\n",
    "\n",
    "# run agent with context\n",
    "response = await agent.run(\"My name is Logan\", ctx=ctx)\n",
    "response = await agent.run(\"What is my name?\", ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "# Create a RAG tool using LlamaIndex\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Useful for multiplying two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def search_documents(query: str) -> str:\n",
    "    \"\"\"Useful for answering natural language questions about an personal essay written by Paul Graham.\"\"\"\n",
    "    response = await query_engine.aquery(query)\n",
    "    return str(response)\n",
    "\n",
    "\n",
    "# Create an enhanced workflow with both tools\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    [multiply, search_documents],\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    system_prompt=\"\"\"You are a helpful assistant that can perform calculations\n",
    "    and search through documents to answer questions.\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "# Now we can ask questions about the documents or do calculations\n",
    "async def main():\n",
    "    response = await agent.run(\"What did the author do in college? Also, what's 7 * 8?\")\n",
    "    print(response)\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting agno\n",
      "  Using cached agno-1.1.2-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting docstring-parser (from agno)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: gitpython in /opt/homebrew/lib/python3.11/site-packages (from agno) (3.1.42)\n",
      "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.11/site-packages (from agno) (0.27.2)\n",
      "Collecting pydantic-settings (from agno)\n",
      "  Using cached pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pydantic in /opt/homebrew/lib/python3.11/site-packages (from agno) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (from agno) (1.0.1)\n",
      "Requirement already satisfied: python-multipart in /opt/homebrew/lib/python3.11/site-packages (from agno) (0.0.9)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.11/site-packages (from agno) (6.0.2)\n",
      "Requirement already satisfied: rich in /opt/homebrew/lib/python3.11/site-packages (from agno) (13.9.4)\n",
      "Collecting tomli (from agno)\n",
      "  Using cached tomli-2.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typer in /opt/homebrew/lib/python3.11/site-packages (from agno) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from agno) (4.12.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/lib/python3.11/site-packages (from gitpython->agno) (4.0.11)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.11/site-packages (from httpx->agno) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx->agno) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx->agno) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx->agno) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from httpx->agno) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx->agno) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic->agno) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic->agno) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->agno) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/cvk/Library/Python/3.11/lib/python/site-packages (from rich->agno) (2.15.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/lib/python3.11/site-packages (from typer->agno) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typer->agno) (1.5.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/homebrew/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->agno) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->agno) (0.1.2)\n",
      "Using cached agno-1.1.2-py3-none-any.whl (477 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Using cached tomli-2.2.1-cp311-cp311-macosx_11_0_arm64.whl (123 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tomli, docstring-parser, pydantic-settings, agno\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed agno-1.1.2 docstring-parser-0.16 pydantic-settings-2.7.1 tomli-2.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install agno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e1ec605e3f41f0b783599c499aa1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">游꼴 https://wandb.ai/carlkho-cvk-minerva-university/intro-example/r/call/01950c93-7532-7462-ab98-437dcef63f80\n",
       "</pre>\n"
      ],
      "text/plain": [
       "游꼴 https://wandb.ai/carlkho-cvk-minerva-university/intro-example/r/call/01950c93-7532-7462-ab98-437dcef63f80\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent.print_response(\"1 sentence news story from New York\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting duckduckgo-search\n",
      "  Using cached duckduckgo_search-7.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /opt/homebrew/lib/python3.11/site-packages (from duckduckgo-search) (8.1.8)\n",
      "Collecting primp>=0.11.0 (from duckduckgo-search)\n",
      "  Using cached primp-0.12.1-cp38-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Using cached lxml-5.3.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.7 kB)\n",
      "Using cached duckduckgo_search-7.3.2-py3-none-any.whl (19 kB)\n",
      "Using cached lxml-5.3.1-cp311-cp311-macosx_10_9_universal2.whl (8.2 MB)\n",
      "Using cached primp-0.12.1-cp38-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: primp, lxml, duckduckgo-search\n",
      "  Attempting uninstall: lxml\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: lxml 5.1.0\n",
      "    Uninstalling lxml-5.1.0:\n",
      "      Successfully uninstalled lxml-5.1.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytest (/opt/homebrew/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed duckduckgo-search-7.3.2 lxml-5.3.1 primp-0.12.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2096b893040947719baabf9053cea660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">游꼴 https://wandb.ai/carlkho-cvk-minerva-university/intro-example/r/call/01950c95-2a08-71a0-9492-ccdf467244e6\n",
       "</pre>\n"
      ],
      "text/plain": [
       "游꼴 https://wandb.ai/carlkho-cvk-minerva-university/intro-example/r/call/01950c95-2a08-71a0-9492-ccdf467244e6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">游꼴 https://wandb.ai/carlkho-cvk-minerva-university/intro-example/r/call/01950c95-3687-71a1-aa39-2369dcd51809\n",
       "</pre>\n"
      ],
      "text/plain": [
       "游꼴 https://wandb.ai/carlkho-cvk-minerva-university/intro-example/r/call/01950c95-3687-71a1-aa39-2369dcd51809\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent.print_response(\"Share a news story from New York.\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
